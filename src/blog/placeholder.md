---
title: "placeholder"
slug: "placeholder"
pubDate: "2025-12-05"
author: "Becky Schmidt"
description: "Why enterprise AI experience matters more than side projects, and what I'm focusing on as an AI product manager in 2026."
tags: ["AI","product management"]
---
This [LinkedIn](https://www.linkedin.com/posts/gomeschris_over-the-past-7-months-ive-hired-4-product-activity-7401947586292621312-owBg?utm_source=share&utm_medium=member_desktop&rcm=ACoAABYyuN8BiBAN0-xUJvZwebVfsZH4peYEMsg) post from Christopher Gomes really caught my attention as a super honest writeup of hiring for AI PMs in 2025. He's the VP of Product at [Conveyor](https://www.conveyor.com/).

> Over the past 7 months I've hired 4 Product Managers, all with depth in AI, into Conveyor (Series B). The last time I had hired PMs was 2020. It was eye-opening, to say the least, to learn as a hiring manager how much the PM career path had changed since then.
>
> First, some stats:
> - 4 roles ranging from Senior to Principal
> - 1.4k inbound applicants per each JD that we listed on LinkedIn
> - 2 outside recruiters helped source candidates
> - Longest role took 6.5 months to fill
> - For that role we spent $5.3k compensating ppl to complete time-boxed take-homes (reminder that, for a Series B startup, this is a drop in the bucket, and you should be compensating candidates for their time)
> - 2 of the 4 hires we made ended up being people I had personally worked with before
>
> Takeaway # 1 - the alpha of grinding on impactful AI products
>
> For three of the roles, I was seeking PMs who had delivered agentic or LLM-powered experiences to paying customers, with enough time to iterate and yield meaningful business or customer impact. Two years from now, I'm sure that sentence is going to sound like "I was seeking PMs who had touched a keyboard." But in 2025, it was hard to find such candidates, and those candidates were very competitive.
>
> To be sure, the "paying customers" and "enough time" parts excluded many (strong) candidates who simply didn't have that professional experience. Plenty of incredible folks talked about (impressive) apps they had built on the side, or even shared vibe-coded mini-Conveyors.
>
> The reason I stuck with this requirement was that the last 3 years building Conveyor taught me that it is delightfully easy to go from "zero to one" when building AI products/features, and yet quite hard to go from "one to ten" (i.e., to get the performance, predictability, reliability, and so forth to achieve outcomes). Nevertheless, I felt like a meme - the kind of hiring manager Redditors dismantle ("they're seeking 5 years experience in a language that's only been around for 2 years!"). Time will tell if this was the right call or if I was being a doofus.
>
> My point is just for those PMs fortunate enough to be job-seeking while currently employed (not to be taken for granted): your market alpha increases as a result of grinding it out on "that one AI feature" to the point that it's actually useful, and as a result of being able to tell that story to hiring managers.
>
> I recommend Hamel and Shreya's Maven course "AI Evals for Engineers & PMs" if you're unsure what it means to grind it out on AI features. And for hiring managers, I recommend Christopher Lee as a recruiting thought partner (he is a former PM running a firm specializing in PM hiring).
>
> I have 2-3 more takeaways at this level of intelligence/vapidity, which I hope to post at a later date. Maybe the LinkedIn algorithm will be clever enough to show them to you if you've made it this far? Or, let me know in the comments if you want me to reach out to you when I post those.

There's a lot to digest here, but three things really stuck out to me as an AI product manager. These observations mirror what I'm experiencing as I build AI products.

## 1. Enterprise experience is the differentiator

Over the past few months my focus has shifted from "how can I get my hands dirty creating?" to "how can I best guide our existing products into the AI era?"

The first mindset is very indie-hacker-esque and I still greatly enjoy that. I have plenty of small side [projects](/projects) that I'm tinkering with in my free time - most recently, I've been exploring SEO-driven directory sites and experimenting with AI-enabled micro-SaaS. But none of those projects have paying customers, contracts, stakeholders, investors, or employees. They're essentially 0 to 0.5 vibe coding projects, not the 0 to 1 (and beyond) that Christopher is talking about.

At Octane11, I'm working on our core data and AI products in a real enterprise environment, and it's becoming table stakes. This experience, while slower than my personal side projects, is the real "value add" in my career when everyone has access to vibe coding tools.

Product managers working on AI products in 2025 are incredibly early. Not many people have experience taking AI experiences beyond the MVP yet. I'm making sure I push beyond the prototype phase and run our products through the gauntlet - user feedback, iteration, measuring outcomes. It's critical that if you are not working on an AI project that you raise your hand and get on one.

## 2. The signal-to-noise problem is real

1.4k inbound applicants **PER job description**. I wish he had provided some stats on how many of those candidates were immediately disqualified, but either way this volume of applications shows that the PM market is flooded and hiring managers are drowning in applications

For those of us building, it's critical that we get better at documenting and articulating what we're doing. The true edge is not just working on AI, but bringing it to real customers. What were the measureable outcomes? How did you handle the hard parts like customer expectations, security, evals, etc.?

I'm realizing I need to be much more intentional about this. I've been working on our AI chatbot that calls our MCP server to pull real user data and interpret it - technical work that required solving problems around data access, response accuracy, and user experience. It's in the early stages, but this post was a great reminder that beyond building, my job is to also interpret, guide, and measure.

## 3. Real relationships still matter

I almost missed this last point:

> 2 of the 4 hires we made ended up being people I had personally worked with before

This is buried in the stats but it's arguably the most important point. Despite 1,400+ applications per role, half the hires came from existing relationships.

Everyone is using ChatGPT to write resume bullets and cover letters, so authentic connections matter more than ever. AI can't replacing genuine relationships and trust built over time.

This reinforces something I already knew but need to be more proactive about: investing in my current connections, staying in touch with former colleagues, and being someone worth working with again.

## Where I'm focusing

After reading Christopher's post, I felt both energized and a bit anxious. Energized because I'm fortunate to be working on AI products at Octane11 right now, getting that crucial enterprise experience while the field is still so early. Anxious because I can see how competitive this market is becoming, and it's only going to intensify until AI stabilizes (whenever that is).

For the next year, I'm focusing on:
- Owning the roadmap for future AI features at Octane11 and measuring adoption rates for what we ship
- Getting deep into the technicalities of our AI chatbot - understanding our orchestration, how to handle edge cases, how to build reliable AI experiences
- Balancing the scrappy indie hacking I love with the depth of enterprise experience that actually differentiates me in this market
- Remembering that human connection is the real advantage